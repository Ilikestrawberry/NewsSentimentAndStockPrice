{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c02f813-6286-422d-8a97-5ce1eef8f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "class Crawl():\n",
    "    \n",
    "    def __init__(self, client_id, client_secret):\n",
    "\n",
    "        self.client_id = client_id\n",
    "        self.client_secret = client_secret\n",
    "        # self.args = args\n",
    "    \n",
    "    def __call__(self, query, number):\n",
    "\n",
    "        headers = {\n",
    "        \"X-Naver-Client-Id\":self.client_id,\n",
    "        \"X-Naver-Client-Secret\":self.client_secret\n",
    "        }\n",
    "\n",
    "        number_of_iter = (int(number) // 100) + 1\n",
    "\n",
    "        crawl_result = []\n",
    "        start = 1\n",
    "        for i in range(number_of_iter):\n",
    "\n",
    "            if i == (int(number) // 100):\n",
    "                display = int(number) % 100\n",
    "            else:\n",
    "                display = 100\n",
    "            \n",
    "\n",
    "            data = {\n",
    "                'query':query, # 검색어\n",
    "                'display':display, # 검색 개수 default : 10, max : 100\n",
    "                'start':start, # 검색 시작 위치 default : 1, max : 100\n",
    "                # 'sort':date # 검색 결과 정렬 방법 : sim 정확도순, date 날짜순\n",
    "            }\n",
    "            \n",
    "            # 100 단위로 떨어지는 number 값이 들어오면 마지막 iter때 display 값이 0이됨\n",
    "            if display:\n",
    "                data = urllib.parse.urlencode(data)\n",
    "                result = requests.get(\"https://openapi.naver.com/v1/search/news.json?\", headers=headers, params=data)\n",
    "\n",
    "                crawl_result.extend(result.json()['items'])\n",
    "\n",
    "            start += 100\n",
    "\n",
    "        # 아 여기는 원래 본문 없음\n",
    "        crawl_result = pd.DataFrame(crawl_result)\n",
    "        return crawl_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55e181d5-de88-4f11-9c7d-b9e5d0dbd578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50 * 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e98a1319-53ed-4600-8898-8eb313c9a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "def context(x):\n",
    "    try:\n",
    "        article = Article(x, language='ko')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.text\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ade5fbd-8107-4133-a22b-d3612954c592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ### Api Call Start ###\n",
      " ### Parsering start ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:31<00:00,  3.92it/s]\n",
      "100%|██████████| 125/125 [00:33<00:00,  3.75it/s]\n",
      "100%|██████████| 125/125 [00:34<00:00,  3.64it/s]\n",
      "100%|██████████| 125/125 [00:36<00:00,  3.45it/s]\n",
      "100%|██████████| 125/125 [00:36<00:00,  3.40it/s]\n",
      "100%|██████████| 125/125 [00:37<00:00,  3.32it/s]\n",
      "100%|██████████| 125/125 [00:39<00:00,  3.20it/s]\n",
      "100%|██████████| 125/125 [00:43<00:00,  2.88it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m dfp \u001b[38;5;241m=\u001b[39m DataFrameParallel(result, n_cores\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, pbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dfp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(context)\n\u001b[0;32m---> 32\u001b[0m result\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./crawl_set/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mcompany_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39msort\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import requests\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import freeze_support\n",
    "\n",
    "from pandas_parallel_apply import DataFrameParallel\n",
    "\n",
    "# from crawl import Crawl\n",
    "# from context import context\n",
    "import argparse\n",
    "\n",
    "\n",
    "freeze_support()\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--company_name', default='하이닉스')\n",
    "# parser.add_argument('--sort', default='date')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "print(' ### Api Call Start ###')\n",
    "cw = Crawl(client_id = \"TUWK9h7NsYO2gamKnZzO\", client_secret = \"kucd9CcnDn\")\n",
    "result = cw(query='하이닉스', number=1000)\n",
    "\n",
    "print(' ### Parsering start ###')\n",
    "dfp = DataFrameParallel(result, n_cores=16, pbar=True)\n",
    "result['context'] = dfp['link'].apply(context)\n",
    "\n",
    "result.to_pickle(f'./crawl_set/{args.company_name}_{args.sort}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "231fa4cc-ab3c-4322-a254-e1d065f937d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Crawl at 0x7f4a0ed1fb80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ed50596-04d4-4d4b-b83e-c676139b531c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 426\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 426\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m     prepro \u001b[38;5;241m=\u001b[39m Preprocess()\n\u001b[1;32m    429\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample.pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# import kss\n",
    "from soynlp.normalizer import *\n",
    "from collections import OrderedDict\n",
    "\n",
    "from pykospacing import Spacing\n",
    "from hanspell import spell_checker\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "import time\n",
    "class Preprocess:\n",
    "    def __init__(self):\n",
    "\n",
    "        #self.spacing = Spacing()\n",
    "        self.excluded_words = [\"이하 뉴스1\", \"이 줄은 실제 뉴스\"]\n",
    "        self.mecab = Mecab()\n",
    "\n",
    "    def _remove_bold(self, texts):\n",
    "\n",
    "        texts = texts.replace('<b>','')\n",
    "        texts = texts.replace('</b>','')\n",
    "\n",
    "        return texts\n",
    "\n",
    "    def _remove_url_email(self, texts):\n",
    "        pattern_email = re.compile(r'[-_0-9a-z]+@[-_0-9a-z]+(?:\\.[0-9a-z]+)+', flags=re.IGNORECASE)\n",
    "        pattern_url = re.compile(r'(?:https?:\\/\\/)?[-_0-9a-z]+(?:\\.[-_0-9a-z]+)+', flags=re.IGNORECASE)\n",
    "        texts = pattern_email.sub('', texts)\n",
    "        texts = pattern_url.sub('', texts)\n",
    "\n",
    "        return texts\n",
    "\n",
    "    def _remove_bracket(self, texts):\n",
    "\n",
    "        pattern_bracket = re.compile(r'^((?:\\[.+\\])|(?:【.+】)|(?:<.+>)|(?:◆.+◆)\\s)')\n",
    "        texts = pattern_bracket.sub('', texts).strip()\n",
    "\n",
    "        return texts\n",
    "\n",
    "    def _split_context(self, texts):\n",
    "\n",
    "        #context = texts.split(\"\\n\")\n",
    "\n",
    "        context = sent_tokenize(texts)\n",
    "        return context\n",
    "\n",
    "    def _remove_html(self, texts):\n",
    "\n",
    "        \"\"\"\n",
    "        HTML 태그를 제거합니다.\n",
    "        ``<p>안녕하세요 ㅎㅎ </p>`` -> ``안녕하세요 ㅎㅎ ``\n",
    "        \"\"\"\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            text = re.sub(r\"<[^>]+>\\s+(?=<)|<[^>]+>\", \"\", text).strip()\n",
    "            if text:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _remove_email(self, texts):\n",
    "        \"\"\"\n",
    "        이메일을 제거합니다.\n",
    "        ``홍길동 abc@gmail.com 연락주세요!`` -> ``홍길동  연락주세요!``\n",
    "        \"\"\"\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            text = re.sub(\n",
    "                r\"[a-zA-Z0-9+-_.]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", \"\", text\n",
    "            ).strip()\n",
    "            if text:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _remove_hashtag(self, texts):\n",
    "        \"\"\"\n",
    "        해쉬태그(#)를 제거합니다.\n",
    "        ``대박! #맛집 #JMT`` -> ``대박!  ``\n",
    "        \"\"\"\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            text = re.sub(r\"#\\S+\", \"\", text).strip()\n",
    "            if text:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _remove_user_mention(self, texts):\n",
    "        \"\"\"\n",
    "        유저에 대한 멘션(@) 태그를 제거합니다.\n",
    "        ``@홍길동 감사합니다!`` -> `` 감사합니다!``\n",
    "        \"\"\"\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            text = re.sub(r\"@\\w+\", \"\", text).strip()\n",
    "            if text:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _remove_url(self, texts):\n",
    "        \"\"\"\n",
    "        URL을 제거합니다.\n",
    "        ``주소: www.naver.com`` -> ``주소: ``\n",
    "        \"\"\"\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            text = re.sub(r\"(http|https)?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"\", text).strip()\n",
    "            text = re.sub(r\"pic\\.(\\w+\\.)+\\S*\", \"\", text).strip()\n",
    "            if text:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _remove_bad_char(self, texts):\n",
    "        \"\"\"\n",
    "        문제를 일으킬 수 있는 문자들을 제거합니다.\n",
    "        \"\"\"\n",
    "        bad_chars = {\"\\u200b\": \"\", \"…\": \" ... \", \"\\ufeff\": \"\"}\n",
    "        preprcessed_text = []\n",
    "        for text in texts:\n",
    "            for bad_char in bad_chars:\n",
    "                text = text.replace(bad_char, bad_chars[bad_char])\n",
    "            text = re.sub(r\"[\\+á?\\xc3\\xa1]\", \"\", text)\n",
    "            if text:\n",
    "                preprcessed_text.append(text)\n",
    "        return preprcessed_text\n",
    "\n",
    "    def _remove_press(self, texts):\n",
    "        \"\"\"\n",
    "        언론 정보를 제거합니다.\n",
    "        ``홍길동 기자 (연합뉴스)`` -> ````\n",
    "        ``(이스탄불=연합뉴스) 하채림 특파원 -> ````\n",
    "        \"\"\"\n",
    "        re_patterns = [\n",
    "            r\"\\([^(]*?(뉴스|경제|일보|미디어|데일리|한겨례|타임즈|위키트리)\\)\",\n",
    "            r\"[가-힣]{0,5} (기자|선임기자|수습기자|특파원|객원기자|논설고문|통신원|연구소장) \",  # 이름 + 기자\n",
    "            r\"[가-힣]{1,}(뉴스|경제|일보|미디어|데일리|한겨례|타임|위키트리)\",  # (... 연합뉴스) ..\n",
    "            r\"\\(\\s+\\)\",  # (  )\n",
    "            r\"\\(=\\s+\\)\",  # (=  )\n",
    "            r\"\\(\\s+=\\)\",  # (  =)\n",
    "        ]\n",
    "\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            for re_pattern in re_patterns:\n",
    "                text = re.sub(re_pattern, \"\", text).strip()\n",
    "            if text:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _remove_copyright(self, texts):\n",
    "        \"\"\"\n",
    "        뉴스 내 포함된 저작권 관련 텍스트를 제거합니다.\n",
    "        ``(사진=저작권자(c) 연합뉴스, 무단 전재-재배포 금지)`` -> ``(사진= 연합뉴스, 무단 전재-재배포 금지)`` TODO 수정할 것\n",
    "        \"\"\"\n",
    "        re_patterns = [\n",
    "            r\"\\<저작권자(\\(c\\)|ⓒ|©|\\(Copyright\\)|(\\(c\\))|(\\(C\\))).+?\\>\",\n",
    "            r\"저작권자\\(c\\)|ⓒ|©|(Copyright)|(\\(c\\))|(\\(C\\))\",\n",
    "        ]\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            for re_pattern in re_patterns:\n",
    "                text = re.sub(re_pattern, \"\", text).strip()\n",
    "            if text:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _remove_photo_info(self, texts):\n",
    "        \"\"\"\n",
    "        뉴스 내 포함된 이미지에 대한 label을 제거합니다.\n",
    "        ``(사진= 연합뉴스, 무단 전재-재배포 금지)`` -> ````\n",
    "        ``(출처=청주시)`` -> ````\n",
    "        \"\"\"\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            text = re.sub(\n",
    "                r\"\\(출처 ?= ?.+\\) |\\(사진 ?= ?.+\\) |\\(자료 ?= ?.+\\)| \\(자료사진\\) |사진=.+기자 \",\n",
    "                \"\",\n",
    "                text,\n",
    "            ).strip()\n",
    "            if text:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _remove_useless_breacket(self, texts):\n",
    "        \"\"\"\n",
    "        위키피디아 전처리를 위한 함수입니다.\n",
    "        괄호 내부에 의미가 없는 정보를 제거합니다.\n",
    "        아무런 정보를 포함하고 있지 않다면, 괄호를 통채로 제거합니다.\n",
    "        ``수학(,)`` -> ``수학``\n",
    "        ``수학(數學,) -> ``수학(數學)``\n",
    "        \"\"\"\n",
    "        bracket_pattern = re.compile(r\"\\((.*?)\\)\")\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            modi_text = \"\"\n",
    "            text = text.replace(\"()\", \"\")  # 수학() -> 수학\n",
    "            brackets = bracket_pattern.search(text)\n",
    "            if not brackets:\n",
    "                if text:\n",
    "                    preprocessed_text.append(text)\n",
    "                    continue\n",
    "            replace_brackets = {}\n",
    "            # key: 원본 문장에서 고쳐야하는 index, value: 고쳐져야 하는 값\n",
    "            # e.g. {'2,8': '(數學)','34,37': ''}\n",
    "            while brackets:\n",
    "                index_key = str(brackets.start()) + \",\" + str(brackets.end())\n",
    "                bracket = text[brackets.start() + 1 : brackets.end() - 1]\n",
    "                infos = bracket.split(\",\")\n",
    "                modi_infos = []\n",
    "                for info in infos:\n",
    "                    info = info.strip()\n",
    "                    if len(info) > 0:\n",
    "                        modi_infos.append(info)\n",
    "                if len(modi_infos) > 0:\n",
    "                    replace_brackets[index_key] = \"(\" + \", \".join(modi_infos) + \")\"\n",
    "                else:\n",
    "                    replace_brackets[index_key] = \"\"\n",
    "                brackets = bracket_pattern.search(text, brackets.start() + 1)\n",
    "            end_index = 0\n",
    "            for index_key in replace_brackets.keys():\n",
    "                start_index = int(index_key.split(\",\")[0])\n",
    "                modi_text += text[end_index:start_index]\n",
    "                modi_text += replace_brackets[index_key]\n",
    "                end_index = int(index_key.split(\",\")[1])\n",
    "            modi_text += text[end_index:]\n",
    "            modi_text = modi_text.strip()\n",
    "            if modi_text:\n",
    "                preprocessed_text.append(modi_text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _remove_repeat_char(self, texts):\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            text = repeat_normalize(text, num_repeats=2).strip()\n",
    "            if text:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _clean_punc(self, texts):\n",
    "        punct_mapping = {\n",
    "            \"‘\": \"'\",\n",
    "            \"₹\": \"e\",\n",
    "            \"´\": \"'\",\n",
    "            \"°\": \"\",\n",
    "            \"€\": \"e\",\n",
    "            \"™\": \"tm\",\n",
    "            \"√\": \" sqrt \",\n",
    "            \"×\": \"x\",\n",
    "            \"²\": \"2\",\n",
    "            \"—\": \"-\",\n",
    "            \"–\": \"-\",\n",
    "            \"’\": \"'\",\n",
    "            \"_\": \"-\",\n",
    "            \"`\": \"'\",\n",
    "            \"“\": '\"',\n",
    "            \"”\": '\"',\n",
    "            \"“\": '\"',\n",
    "            \"£\": \"e\",\n",
    "            \"∞\": \"infinity\",\n",
    "            \"θ\": \"theta\",\n",
    "            \"÷\": \"/\",\n",
    "            \"α\": \"alpha\",\n",
    "            \"•\": \".\",\n",
    "            \"à\": \"a\",\n",
    "            \"−\": \"-\",\n",
    "            \"β\": \"beta\",\n",
    "            \"∅\": \"\",\n",
    "            \"³\": \"3\",\n",
    "            \"π\": \"pi\",\n",
    "        }\n",
    "\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            for p in punct_mapping:\n",
    "                text = text.replace(p, punct_mapping[p])\n",
    "            text = text.strip()\n",
    "            if text:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _remove_repeated_spacing(self, texts):\n",
    "        \"\"\"\n",
    "        두 개 이상의 연속된 공백을 하나로 치환합니다.\n",
    "        ``오늘은    날씨가   좋다.`` -> ``오늘은 날씨가 좋다.``\n",
    "        \"\"\"\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "            if text:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _remove_dup_sent(self, texts):\n",
    "        \"\"\"\n",
    "        중복된 문장을 제거합니다.\n",
    "        \"\"\"\n",
    "        texts = list(OrderedDict.fromkeys(texts))\n",
    "        return texts\n",
    "\n",
    "    def _spacing_sent(self, texts):\n",
    "        \"\"\"\n",
    "        띄어쓰기를 보정합니다.\n",
    "        \"\"\"\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            text = self.spacing(text)\n",
    "            if text:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _spell_check_sent(self, texts):\n",
    "        \"\"\"\n",
    "        맞춤법을 보정합니다.\n",
    "        \"\"\"\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            try:\n",
    "                spelled_sent = spell_checker.check(text)\n",
    "                checked_sent = spelled_sent.checked\n",
    "                if checked_sent:\n",
    "                    preprocessed_text.append(checked_sent)\n",
    "            except:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _excluded_word_filter(self, texts):\n",
    "        \"\"\"\n",
    "        특정 단어를 포함하는 문장 필터링\n",
    "        \"\"\"\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            include_flag = False\n",
    "            for word in self.excluded_words:\n",
    "                if word in text:\n",
    "                    include_flag = True\n",
    "                    break\n",
    "            if not include_flag:\n",
    "                preprocessed_text.append(text)\n",
    "        return preprocessed_text\n",
    "\n",
    "    # def _additional_filter(self, texts):\n",
    "\n",
    "\n",
    "    #     preprocessed_text = []\n",
    "    #     for text in texts:\n",
    "\n",
    "    def _morph_filter(self, texts):\n",
    "        \"\"\"\n",
    "        명사(NN), 동사(V), 형용사(J)의 포함 여부에 따라 문장 필터링\n",
    "        \"\"\"\n",
    "        NN_TAGS = [\"NNG\", \"NNP\", \"NNB\", \"NP\"]\n",
    "        V_TAGS = [\"VV\", \"VA\", \"VX\", \"VCP\", \"VCN\", \"XSN\", \"XSA\", \"XSV\"]\n",
    "        J_TAGS = [\"JKS\", \"J\", \"JO\", \"JK\", \"JKC\", \"JKG\", \"JKB\", \"JKV\", \"JKQ\", \"JX\", \"JC\", \"JKI\", \"JKO\", \"JKM\", \"ETM\"]\n",
    "\n",
    "        preprocessed_text = []\n",
    "        for text in texts:\n",
    "            morphs = self.mecab.pos(text, join=False)\n",
    "\n",
    "            nn_flag = False\n",
    "            v_flag = False\n",
    "            j_flag = False\n",
    "            for morph in morphs:\n",
    "                pos_tags = morph[1].split(\"+\")\n",
    "                for pos_tag in pos_tags:\n",
    "                    if not nn_flag and pos_tag in NN_TAGS:\n",
    "                        nn_flag = True\n",
    "                    if not v_flag and pos_tag in V_TAGS:\n",
    "                        v_flag = True\n",
    "                    if not j_flag and pos_tag in J_TAGS:\n",
    "                        j_flag = True\n",
    "                if nn_flag and v_flag and j_flag:\n",
    "                    preprocessed_text.append(text)\n",
    "                    break\n",
    "        return preprocessed_text\n",
    "\n",
    "    def _remove_stopwords(self, sents):\n",
    "        #  큰 의미가 없는 불용어 정의\n",
    "        #  사용자가 자체적으로 stopwords를 정희하면 될 듯\n",
    "        stopwords = [\"소취요\", \"-\", \"조드윅\", \"포스터\", \"앓는\", \"서린\"]\n",
    "        preprocessed_text = []\n",
    "        for sent in sents:\n",
    "            sent = [w for w in sent.split(\" \") if w not in stopwords]  # 불용어 제거\n",
    "            preprocessed_text.append(\" \".join(sent))\n",
    "        return preprocessed_text\n",
    "\n",
    "    def __call__(self, text):\n",
    "\n",
    "        if text != None:\n",
    "\n",
    "            context = text\n",
    "            context = self._remove_bold(context)\n",
    "            context = self._remove_url_email(context)\n",
    "            context = self._remove_bracket(context)\n",
    "            context = self._split_context(context)\n",
    "            context = self._remove_html(context)\n",
    "            #context = self._remove_email(context)\n",
    "            context = self._remove_hashtag(context)\n",
    "            context = self._remove_user_mention(context)\n",
    "            #context = self._remove_url(context)\n",
    "            context = self._remove_bad_char(context)\n",
    "            context = self._remove_press(context)\n",
    "            context = self._remove_copyright(context)\n",
    "            context = self._remove_photo_info(context)\n",
    "            context = self._remove_useless_breacket(context)\n",
    "            context = self._remove_repeat_char(context)\n",
    "            context = self._clean_punc(context)\n",
    "            context = self._remove_repeated_spacing(context)\n",
    "            context = self._remove_dup_sent(context)\n",
    "            # #context = self._spacing_sent(context)\n",
    "            # context = self._spell_check_sent(context)\n",
    "            # context = self._excluded_word_filter(context)\n",
    "            # context = self._remove_stopwords(context)\n",
    "            # context = self._morph_filter(context)\n",
    "\n",
    "            return context\n",
    "\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    sample = pd.read_pickle('sample.pkl')\n",
    "    prepro = Preprocess()\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = prepro(sample.iloc[0])\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(result)\n",
    "    print('time check', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5726dd25-25ac-4a19-a614-201448b55d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      광주·전남 &quot;반도체 특화단지 여기가 적지입니다&quot;··· 장점 강조하...\n",
       "1         [증시] 코스피, 개인·기관 매수에 소폭 상승…외인 순매도 상위 종목은 LG화...\n",
       "2                        코스피, 개인·기관 매수에 소폭 상승...2450선 마감\n",
       "3             [20일 마감시황] 코스피, 개인·기관 매수에 소폭 상승…2455.12 마감\n",
       "4        美 정부 반도체 지원팀에 SK<b>하이닉스</b> 전 부사장 합류…역대급 로비 통했나\n",
       "                             ...                        \n",
       "995                       [정범구 칼럼] 예측 불가한 세계, 지속 가능한 지구?\n",
       "996                               기재위서 막힌 반도체 설비투자 세액공제법\n",
       "997                  용인 반도체클러스터 핵심기반시설 조성 &apos;순항&apos;\n",
       "998               개미들 &apos;삼성전자 사랑&apos; 결실…주주 60%가 수익권\n",
       "999       국회 &apos;K칩스법&apos; 논의 착수했지만…野 반대로 2월 통과는 가시밭길\n",
       "Name: title, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15eeb025-430e-40be-b17b-5072986cac0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['광주·전남 &quot;반도체 특화단지 여기가 적지입니다&quot;··· 장점 강조하며 구애']\n",
      "time check 0.013570547103881836\n"
     ]
    }
   ],
   "source": [
    "prepro = Preprocess()\n",
    "\n",
    "start_time = time.time()\n",
    "result = prepro(result['title'][0])\n",
    "end_time = time.time()\n",
    "\n",
    "print(result)\n",
    "print('time check', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d20aca2c-7ec0-4de2-9a81-89cb8251eb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"'가나\"[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab0276b9-fff6-43da-bf89-fc94a886221a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>originallink</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>광주·전남 &amp;quot;반도체 특화단지 여기가 적지입니다&amp;quot;··· 장점 강조하...</td>\n",
       "      <td>http://www.mdilbo.com/detail/0kIA7d/689063</td>\n",
       "      <td>http://www.mdilbo.com/detail/0kIA7d/689063</td>\n",
       "      <td>전 &lt;b&gt;하이닉스&lt;/b&gt; 반도체 총괄팀장을 단장으로 채용했다. 같은 달 반도체산업과...</td>\n",
       "      <td>Mon, 20 Feb 2023 17:28:00 +0900</td>\n",
       "      <td>산업통상자원부는 반도체와 디스플레이, 이차전지를 국가 첨단전략산업으로 정하고 세부 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[증시] 코스피, 개인·기관 매수에 소폭 상승…외인 순매도 상위 종목은 LG화...</td>\n",
       "      <td>http://www.topstarnews.net/news/articleView.ht...</td>\n",
       "      <td>http://www.topstarnews.net/news/articleView.ht...</td>\n",
       "      <td>삼성전자(0.16%)와 SK&lt;b&gt;하이닉스&lt;/b&gt;(0.54%) 등 반도체주는 소폭 올...</td>\n",
       "      <td>Mon, 20 Feb 2023 17:28:00 +0900</td>\n",
       "      <td>[표] 외인 매수 매도 종목\\n\\n[표] 기관 매수 매도 종목\\n\\n[표] 코스피 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>코스피, 개인·기관 매수에 소폭 상승...2450선 마감</td>\n",
       "      <td>http://www.paxetv.com/news/articleView.html?id...</td>\n",
       "      <td>http://www.paxetv.com/news/articleView.html?id...</td>\n",
       "      <td>코스피 시가총액 상위 10개 종목 중 NAVER(1.62%), 삼성바이오로직스(0....</td>\n",
       "      <td>Mon, 20 Feb 2023 17:20:00 +0900</td>\n",
       "      <td>코스피가 개인과 기관 순매수에 소폭 상승해 강보합권인 2450대에서 장을 마감했습니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[20일 마감시황] 코스피, 개인·기관 매수에 소폭 상승…2455.12 마감</td>\n",
       "      <td>http://www.newsworks.co.kr/news/articleView.ht...</td>\n",
       "      <td>http://www.newsworks.co.kr/news/articleView.ht...</td>\n",
       "      <td>코스피 시가총액 상위 10개 종목 중 ▲삼성전자(0.16%) ▲SK&lt;b&gt;하이닉스&lt;/...</td>\n",
       "      <td>Mon, 20 Feb 2023 17:18:00 +0900</td>\n",
       "      <td>(사진=KRX 정보데이터시스템 캡처)\\n\\n[뉴스웍스=유한새 기자] 코스피는 개인과...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>美 정부 반도체 지원팀에 SK&lt;b&gt;하이닉스&lt;/b&gt; 전 부사장 합류…역대급 로비 통했나</td>\n",
       "      <td>https://biz.chosun.com/it-science/ict/2023/02/...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/366/000...</td>\n",
       "      <td>댄 김 전 SK&lt;b&gt;하이닉스&lt;/b&gt; 미주 부사장 반도체팀 전략기획 책임자로 임명 삼...</td>\n",
       "      <td>Mon, 20 Feb 2023 17:16:00 +0900</td>\n",
       "      <td>미국 정부가 반도체지원법(CHIPS and Science Act) 보조금 지원을 감...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[정범구 칼럼] 예측 불가한 세계, 지속 가능한 지구?</td>\n",
       "      <td>http://www.mygoyang.com/news/articleView.html?...</td>\n",
       "      <td>http://www.mygoyang.com/news/articleView.html?...</td>\n",
       "      <td>[출처=EKOenergy] 당장 애플사는 협력기업들에게 2030년까지 RE100을 ...</td>\n",
       "      <td>Tue, 14 Feb 2023 17:58:00 +0900</td>\n",
       "      <td>[고양신문] 2019년 말, 중국 우한에서 이름 모를 괴질로 사망자가 발생했을 때 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>기재위서 막힌 반도체 설비투자 세액공제법</td>\n",
       "      <td>http://www.dt.co.kr/contents.html?article_no=2...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/029/000...</td>\n",
       "      <td>장혜영 정의당 의원은 &amp;quot;투자를 촉진한다는 법안 제도 취지는 좋지만 사실상 ...</td>\n",
       "      <td>Tue, 14 Feb 2023 17:56:00 +0900</td>\n",
       "      <td>국회가 국내 반도체 산업 활성화를 위해 반도체 투자 세액공제율을 15%까지 상향하는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>용인 반도체클러스터 핵심기반시설 조성 &amp;apos;순항&amp;apos;</td>\n",
       "      <td>http://www.incheonilbo.com/news/articleView.ht...</td>\n",
       "      <td>http://www.incheonilbo.com/news/articleView.ht...</td>\n",
       "      <td>용인 반도체클러스터는 사업시행자인 용인일반산업단지(주)가 처인구 원삼면 일원에 약4...</td>\n",
       "      <td>Tue, 14 Feb 2023 17:56:00 +0900</td>\n",
       "      <td>전력공급시설 공사 공정률 17%\\n\\n용수 공급 관로 설치도 본격화\\n\\n2027년...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>개미들 &amp;apos;삼성전자 사랑&amp;apos; 결실…주주 60%가 수익권</td>\n",
       "      <td>https://www.sedaily.com/NewsView/29LQZ3OO7H</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/011/000...</td>\n",
       "      <td>SK&lt;b&gt;하이닉스&lt;/b&gt;(000660)에 대한 투자는 분위기가 사뭇 달랐다. 현재 ...</td>\n",
       "      <td>Tue, 14 Feb 2023 17:54:00 +0900</td>\n",
       "      <td>삼성전자(005930)\\n\\nSK하이닉스(000660)\\n\\n[서울경제]‘국민주’가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>국회 &amp;apos;K칩스법&amp;apos; 논의 착수했지만…野 반대로 2월 통과는 가시밭길</td>\n",
       "      <td>https://www.sedaily.com/NewsView/29LQYHZ7MA</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/011/000...</td>\n",
       "      <td>장혜영 정의당 의원도 “투자를 촉진한다는 법안 제도 취지는 좋지만 사실상 (반도체 ...</td>\n",
       "      <td>Tue, 14 Feb 2023 17:51:00 +0900</td>\n",
       "      <td>[서울경제]정부가 반도체 기업 투자세액공제 추가 확대안을 발의한 지 약 한 달 만에...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    광주·전남 &quot;반도체 특화단지 여기가 적지입니다&quot;··· 장점 강조하...   \n",
       "1       [증시] 코스피, 개인·기관 매수에 소폭 상승…외인 순매도 상위 종목은 LG화...   \n",
       "2                      코스피, 개인·기관 매수에 소폭 상승...2450선 마감   \n",
       "3           [20일 마감시황] 코스피, 개인·기관 매수에 소폭 상승…2455.12 마감   \n",
       "4      美 정부 반도체 지원팀에 SK<b>하이닉스</b> 전 부사장 합류…역대급 로비 통했나   \n",
       "..                                                 ...   \n",
       "995                     [정범구 칼럼] 예측 불가한 세계, 지속 가능한 지구?   \n",
       "996                             기재위서 막힌 반도체 설비투자 세액공제법   \n",
       "997                용인 반도체클러스터 핵심기반시설 조성 &apos;순항&apos;   \n",
       "998             개미들 &apos;삼성전자 사랑&apos; 결실…주주 60%가 수익권   \n",
       "999     국회 &apos;K칩스법&apos; 논의 착수했지만…野 반대로 2월 통과는 가시밭길   \n",
       "\n",
       "                                          originallink  \\\n",
       "0           http://www.mdilbo.com/detail/0kIA7d/689063   \n",
       "1    http://www.topstarnews.net/news/articleView.ht...   \n",
       "2    http://www.paxetv.com/news/articleView.html?id...   \n",
       "3    http://www.newsworks.co.kr/news/articleView.ht...   \n",
       "4    https://biz.chosun.com/it-science/ict/2023/02/...   \n",
       "..                                                 ...   \n",
       "995  http://www.mygoyang.com/news/articleView.html?...   \n",
       "996  http://www.dt.co.kr/contents.html?article_no=2...   \n",
       "997  http://www.incheonilbo.com/news/articleView.ht...   \n",
       "998        https://www.sedaily.com/NewsView/29LQZ3OO7H   \n",
       "999        https://www.sedaily.com/NewsView/29LQYHZ7MA   \n",
       "\n",
       "                                                  link  \\\n",
       "0           http://www.mdilbo.com/detail/0kIA7d/689063   \n",
       "1    http://www.topstarnews.net/news/articleView.ht...   \n",
       "2    http://www.paxetv.com/news/articleView.html?id...   \n",
       "3    http://www.newsworks.co.kr/news/articleView.ht...   \n",
       "4    https://n.news.naver.com/mnews/article/366/000...   \n",
       "..                                                 ...   \n",
       "995  http://www.mygoyang.com/news/articleView.html?...   \n",
       "996  https://n.news.naver.com/mnews/article/029/000...   \n",
       "997  http://www.incheonilbo.com/news/articleView.ht...   \n",
       "998  https://n.news.naver.com/mnews/article/011/000...   \n",
       "999  https://n.news.naver.com/mnews/article/011/000...   \n",
       "\n",
       "                                           description  \\\n",
       "0    전 <b>하이닉스</b> 반도체 총괄팀장을 단장으로 채용했다. 같은 달 반도체산업과...   \n",
       "1    삼성전자(0.16%)와 SK<b>하이닉스</b>(0.54%) 등 반도체주는 소폭 올...   \n",
       "2    코스피 시가총액 상위 10개 종목 중 NAVER(1.62%), 삼성바이오로직스(0....   \n",
       "3    코스피 시가총액 상위 10개 종목 중 ▲삼성전자(0.16%) ▲SK<b>하이닉스</...   \n",
       "4    댄 김 전 SK<b>하이닉스</b> 미주 부사장 반도체팀 전략기획 책임자로 임명 삼...   \n",
       "..                                                 ...   \n",
       "995  [출처=EKOenergy] 당장 애플사는 협력기업들에게 2030년까지 RE100을 ...   \n",
       "996  장혜영 정의당 의원은 &quot;투자를 촉진한다는 법안 제도 취지는 좋지만 사실상 ...   \n",
       "997  용인 반도체클러스터는 사업시행자인 용인일반산업단지(주)가 처인구 원삼면 일원에 약4...   \n",
       "998  SK<b>하이닉스</b>(000660)에 대한 투자는 분위기가 사뭇 달랐다. 현재 ...   \n",
       "999  장혜영 정의당 의원도 “투자를 촉진한다는 법안 제도 취지는 좋지만 사실상 (반도체 ...   \n",
       "\n",
       "                             pubDate  \\\n",
       "0    Mon, 20 Feb 2023 17:28:00 +0900   \n",
       "1    Mon, 20 Feb 2023 17:28:00 +0900   \n",
       "2    Mon, 20 Feb 2023 17:20:00 +0900   \n",
       "3    Mon, 20 Feb 2023 17:18:00 +0900   \n",
       "4    Mon, 20 Feb 2023 17:16:00 +0900   \n",
       "..                               ...   \n",
       "995  Tue, 14 Feb 2023 17:58:00 +0900   \n",
       "996  Tue, 14 Feb 2023 17:56:00 +0900   \n",
       "997  Tue, 14 Feb 2023 17:56:00 +0900   \n",
       "998  Tue, 14 Feb 2023 17:54:00 +0900   \n",
       "999  Tue, 14 Feb 2023 17:51:00 +0900   \n",
       "\n",
       "                                               context  \n",
       "0    산업통상자원부는 반도체와 디스플레이, 이차전지를 국가 첨단전략산업으로 정하고 세부 ...  \n",
       "1    [표] 외인 매수 매도 종목\\n\\n[표] 기관 매수 매도 종목\\n\\n[표] 코스피 ...  \n",
       "2    코스피가 개인과 기관 순매수에 소폭 상승해 강보합권인 2450대에서 장을 마감했습니...  \n",
       "3    (사진=KRX 정보데이터시스템 캡처)\\n\\n[뉴스웍스=유한새 기자] 코스피는 개인과...  \n",
       "4    미국 정부가 반도체지원법(CHIPS and Science Act) 보조금 지원을 감...  \n",
       "..                                                 ...  \n",
       "995  [고양신문] 2019년 말, 중국 우한에서 이름 모를 괴질로 사망자가 발생했을 때 ...  \n",
       "996  국회가 국내 반도체 산업 활성화를 위해 반도체 투자 세액공제율을 15%까지 상향하는...  \n",
       "997  전력공급시설 공사 공정률 17%\\n\\n용수 공급 관로 설치도 본격화\\n\\n2027년...  \n",
       "998  삼성전자(005930)\\n\\nSK하이닉스(000660)\\n\\n[서울경제]‘국민주’가...  \n",
       "999  [서울경제]정부가 반도체 기업 투자세액공제 추가 확대안을 발의한 지 약 한 달 만에...  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4fc29606-4895-4f0a-a963-638a9af12e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fc065d3-59e7-4653-8580-24221c4a2f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/conda/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/conda/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/conda/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "news1 = pd.read_excel('NewsResult_20220101-20230220.xlsx')\n",
    "news2 = pd.read_excel('NewsResult_20200101-20211231.xlsx')\n",
    "news3 = pd.read_excel('NewsResult_20180101-20191231.xlsx')\n",
    "news4 = pd.read_excel('NewsResult_20150101-20171231.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7993503b-e29e-4f27-9907-2e83f1c66c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.concat([news1, news2, news3, news4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18aa181c-8445-43ff-a804-c9b73ba3d3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58196"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2330caaa-9740-43ea-9e50-d77aa1d0c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news[pd.isna(news['분석제외 여부'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "02fef583-6113-4df9-8eb3-49e055c801f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>뉴스 식별자</th>\n",
       "      <th>일자</th>\n",
       "      <th>언론사</th>\n",
       "      <th>기고자</th>\n",
       "      <th>제목</th>\n",
       "      <th>통합 분류1</th>\n",
       "      <th>통합 분류2</th>\n",
       "      <th>통합 분류3</th>\n",
       "      <th>사건/사고 분류1</th>\n",
       "      <th>사건/사고 분류2</th>\n",
       "      <th>사건/사고 분류3</th>\n",
       "      <th>인물</th>\n",
       "      <th>위치</th>\n",
       "      <th>기관</th>\n",
       "      <th>키워드</th>\n",
       "      <th>특성추출(가중치순 상위 50개)</th>\n",
       "      <th>본문</th>\n",
       "      <th>URL</th>\n",
       "      <th>분석제외 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.101201e+06</td>\n",
       "      <td>20230220</td>\n",
       "      <td>디지털타임스</td>\n",
       "      <td>신하연</td>\n",
       "      <td>외국인 웃고 개미 울고 엇갈린 투자 성적표</td>\n",
       "      <td>경제&gt;증권_증시</td>\n",
       "      <td>경제&gt;외환</td>\n",
       "      <td>경제&gt;부동산</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>김상인</td>\n",
       "      <td>전주,미국</td>\n",
       "      <td>CJ제일제당,한국거래소,SK텔레콤,삼성전자,유가증권,SK하이닉스,삼성SDI,한국전력...</td>\n",
       "      <td>외국인,개미,투자,성적표,종목,외국인,투자자,매수,연초,수익,23.6%,수익률,기간...</td>\n",
       "      <td>외국인,반도체,수익률,코스피,에코프로비엠,연구원,가능성,투자자,sk,상승률,인플레이...</td>\n",
       "      <td>'연초 효과'가 이어지고 있지만 외국인과 개인의 투자 성적표는 극명히 갈리는 모습이...</td>\n",
       "      <td>http://www.dt.co.kr/contents.html?article_no=2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.100101e+06</td>\n",
       "      <td>20230220</td>\n",
       "      <td>KBS</td>\n",
       "      <td>신지수</td>\n",
       "      <td>“챗GPT 열풍을 기회로” 국내 반도체 산업 재도약할까</td>\n",
       "      <td>경제&gt;반도체</td>\n",
       "      <td>경제&gt;유통</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>김우현,김재준</td>\n",
       "      <td>고성</td>\n",
       "      <td>SK하이닉스,네이버,삼성전자,정부</td>\n",
       "      <td>열풍,기회로,재도약,반도체,산업,앵커,챗GPT,대화,인공,지능,돌풍,세계,기업들,A...</td>\n",
       "      <td>반도체,ai,차세대,부사장,콘퍼런스콜,삼성전자,고속연산,gpu,챗gpt,하이닉스,고...</td>\n",
       "      <td>[앵커]\\n\\n 대화형 인공지능 '챗GPT'의 돌풍 이후, 세계 주요 기업들이 AI...</td>\n",
       "      <td>https://news.kbs.co.kr/news/view.do?ncd=760948...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.100501e+06</td>\n",
       "      <td>20230220</td>\n",
       "      <td>파이낸셜뉴스</td>\n",
       "      <td>김동호 기자 (hoya0222@fnnews.com)</td>\n",
       "      <td>치매 어르신 찾아주는 SK하이닉스, 기술에 온기를 담다</td>\n",
       "      <td>지역&gt;대전</td>\n",
       "      <td>사회&gt;장애인</td>\n",
       "      <td>지역&gt;충남</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>조모,곽노정</td>\n",
       "      <td>올림피아드,오학동,충남,하인슈타인,하인슈타인 프로젝트,여주시,경기도,이천,보령,청주...</td>\n",
       "      <td>보건복지부,독거노인종합지원,행복모아,푸르메재단,SPC삼립,하이닉스,SK하이닉스,장애...</td>\n",
       "      <td>치매,어르신,SK하이닉스,온기,지역,사회,행복,자발,기부,임직원,12년,온정,7만,...</td>\n",
       "      <td>장애인,하이닉스,sk하이닉스,사업장,발달장애인,배회감지기,지역사회,제과제빵,관계자,...</td>\n",
       "      <td>지역사회 행복 위해 자발적 기부 나선 임직원 \\n12년간 297억 온정 모여 7만7...</td>\n",
       "      <td>http://www.fnnews.com/news/202302201911016525</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.100601e+06</td>\n",
       "      <td>20230220</td>\n",
       "      <td>한국경제</td>\n",
       "      <td>임현우</td>\n",
       "      <td>32% vs 12% 반도체ETF 수익률 천차만별</td>\n",
       "      <td>경제&gt;반도체</td>\n",
       "      <td>경제&gt;증권_증시</td>\n",
       "      <td>경제&gt;유통</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>대만,미국,미국필라델피아반도체나스닥,아시아,일본,중국,한국</td>\n",
       "      <td>ARIRANG,ETP전략팀,KBSTAR,SK하이닉스,SK하이닉스·SK스퀘어·,TIG...</td>\n",
       "      <td>12%,32%,vs,12%,반도체ETF,수익,천차,만별,엔비디아,반도체주,우상향,곡...</td>\n",
       "      <td>반도체,수익률,삼성전자,tiger,엔비디아,삼성증권,한국,etf,sk,하이닉스,연구...</td>\n",
       "      <td>엔비디아 49%, SK하이닉스 21%, TSMC 13% . \\n \\n올 들어 국내외...</td>\n",
       "      <td>https://www.hankyung.com/finance/article/20230...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.600501e+06</td>\n",
       "      <td>20230220</td>\n",
       "      <td>무등일보</td>\n",
       "      <td>선정태</td>\n",
       "      <td>광주 전남 \"반도체 특화단지 여기가 적지입니다\"  장점 강조하며 구애</td>\n",
       "      <td>지역&gt;광주</td>\n",
       "      <td>지역&gt;전남</td>\n",
       "      <td>지역&gt;대전</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>전태영,정성택,윤석열,김종갑</td>\n",
       "      <td>세종시,장성군,전남도,신룡지구,300만평,25만평,광주지역,태양,고려,광주시,제주시...</td>\n",
       "      <td>앰코테크놀로지,추진위원회,담양호,전남도,산업부,육성,하이닉스,인재양성위원회,전남대학...</td>\n",
       "      <td>광주,전남,반도체,특화,적지,장점,강조,구애,첨단,전략,산업,특화,단지,공모,마감,...</td>\n",
       "      <td>반도체,특화단지,광주,전남,지자체,전남도,반도체산업,만큼,전남대학교,설명회,하이닉스...</td>\n",
       "      <td>첨단전략산업 특화단지 공모 마감이 일주일 앞으로 다가오면서 광주 전남을 비롯한 전국...</td>\n",
       "      <td>http://www.mdilbo.com/detail/0kIA7d/689063</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         뉴스 식별자        일자     언론사                           기고자  \\\n",
       "0  7.101201e+06  20230220  디지털타임스                           신하연   \n",
       "1  8.100101e+06  20230220     KBS                           신지수   \n",
       "2  2.100501e+06  20230220  파이낸셜뉴스  김동호 기자 (hoya0222@fnnews.com)   \n",
       "3  2.100601e+06  20230220    한국경제                           임현우   \n",
       "4  1.600501e+06  20230220    무등일보                           선정태   \n",
       "\n",
       "                                       제목    통합 분류1     통합 분류2   통합 분류3  \\\n",
       "0                 외국인 웃고 개미 울고 엇갈린 투자 성적표  경제>증권_증시      경제>외환   경제>부동산   \n",
       "1          “챗GPT 열풍을 기회로” 국내 반도체 산업 재도약할까    경제>반도체      경제>유통      NaN   \n",
       "2          치매 어르신 찾아주는 SK하이닉스, 기술에 온기를 담다     지역>대전     사회>장애인    지역>충남   \n",
       "3              32% vs 12% 반도체ETF 수익률 천차만별    경제>반도체   경제>증권_증시    경제>유통   \n",
       "4  광주 전남 \"반도체 특화단지 여기가 적지입니다\"  장점 강조하며 구애     지역>광주      지역>전남    지역>대전   \n",
       "\n",
       "  사건/사고 분류1 사건/사고 분류2 사건/사고 분류3               인물  \\\n",
       "0       NaN       NaN       NaN              김상인   \n",
       "1       NaN       NaN       NaN          김우현,김재준   \n",
       "2       NaN       NaN       NaN           조모,곽노정   \n",
       "3       NaN       NaN       NaN              NaN   \n",
       "4       NaN       NaN       NaN  전태영,정성택,윤석열,김종갑   \n",
       "\n",
       "                                                  위치  \\\n",
       "0                                              전주,미국   \n",
       "1                                                 고성   \n",
       "2  올림피아드,오학동,충남,하인슈타인,하인슈타인 프로젝트,여주시,경기도,이천,보령,청주...   \n",
       "3                   대만,미국,미국필라델피아반도체나스닥,아시아,일본,중국,한국   \n",
       "4  세종시,장성군,전남도,신룡지구,300만평,25만평,광주지역,태양,고려,광주시,제주시...   \n",
       "\n",
       "                                                  기관  \\\n",
       "0  CJ제일제당,한국거래소,SK텔레콤,삼성전자,유가증권,SK하이닉스,삼성SDI,한국전력...   \n",
       "1                                 SK하이닉스,네이버,삼성전자,정부   \n",
       "2  보건복지부,독거노인종합지원,행복모아,푸르메재단,SPC삼립,하이닉스,SK하이닉스,장애...   \n",
       "3  ARIRANG,ETP전략팀,KBSTAR,SK하이닉스,SK하이닉스·SK스퀘어·,TIG...   \n",
       "4  앰코테크놀로지,추진위원회,담양호,전남도,산업부,육성,하이닉스,인재양성위원회,전남대학...   \n",
       "\n",
       "                                                 키워드  \\\n",
       "0  외국인,개미,투자,성적표,종목,외국인,투자자,매수,연초,수익,23.6%,수익률,기간...   \n",
       "1  열풍,기회로,재도약,반도체,산업,앵커,챗GPT,대화,인공,지능,돌풍,세계,기업들,A...   \n",
       "2  치매,어르신,SK하이닉스,온기,지역,사회,행복,자발,기부,임직원,12년,온정,7만,...   \n",
       "3  12%,32%,vs,12%,반도체ETF,수익,천차,만별,엔비디아,반도체주,우상향,곡...   \n",
       "4  광주,전남,반도체,특화,적지,장점,강조,구애,첨단,전략,산업,특화,단지,공모,마감,...   \n",
       "\n",
       "                                   특성추출(가중치순 상위 50개)  \\\n",
       "0  외국인,반도체,수익률,코스피,에코프로비엠,연구원,가능성,투자자,sk,상승률,인플레이...   \n",
       "1  반도체,ai,차세대,부사장,콘퍼런스콜,삼성전자,고속연산,gpu,챗gpt,하이닉스,고...   \n",
       "2  장애인,하이닉스,sk하이닉스,사업장,발달장애인,배회감지기,지역사회,제과제빵,관계자,...   \n",
       "3  반도체,수익률,삼성전자,tiger,엔비디아,삼성증권,한국,etf,sk,하이닉스,연구...   \n",
       "4  반도체,특화단지,광주,전남,지자체,전남도,반도체산업,만큼,전남대학교,설명회,하이닉스...   \n",
       "\n",
       "                                                  본문  \\\n",
       "0  '연초 효과'가 이어지고 있지만 외국인과 개인의 투자 성적표는 극명히 갈리는 모습이...   \n",
       "1  [앵커]\\n\\n 대화형 인공지능 '챗GPT'의 돌풍 이후, 세계 주요 기업들이 AI...   \n",
       "2  지역사회 행복 위해 자발적 기부 나선 임직원 \\n12년간 297억 온정 모여 7만7...   \n",
       "3  엔비디아 49%, SK하이닉스 21%, TSMC 13% . \\n \\n올 들어 국내외...   \n",
       "4  첨단전략산업 특화단지 공모 마감이 일주일 앞으로 다가오면서 광주 전남을 비롯한 전국...   \n",
       "\n",
       "                                                 URL 분석제외 여부  \n",
       "0  http://www.dt.co.kr/contents.html?article_no=2...     NaN  \n",
       "1  https://news.kbs.co.kr/news/view.do?ncd=760948...     NaN  \n",
       "2      http://www.fnnews.com/news/202302201911016525     NaN  \n",
       "3  https://www.hankyung.com/finance/article/20230...     NaN  \n",
       "4         http://www.mdilbo.com/detail/0kIA7d/689063     NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e66bae8-8dfb-49ac-a079-2b6b4cf31f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['뉴스 식별자', '일자', '언론사', '기고자', '제목', '통합 분류1', '통합 분류2', '통합 분류3',\n",
       "       '사건/사고 분류1', '사건/사고 분류2', '사건/사고 분류3', '인물', '위치', '기관', '키워드',\n",
       "       '특성추출(가중치순 상위 50개)', '본문', 'URL', '분석제외 여부'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca91259d-3583-4a7d-9a87-220344780efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['일자', '제목', '통합 분류1', '통합 분류2', '통합 분류3', '키워드', '특성추출(가중치순 상위 50개)', '본문', 'URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1cef9b02-9654-4c27-9743-c2fbf2db937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news[cols].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "685595b2-84a3-46cf-902e-843aeabb63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce52bf00-6d39-40c0-a8b4-856a4e84bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.to_pickle('하이닉스_news.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e982e7-eec4-4513-bdc4-bad8fba261f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
